#!/bin/bash

#### v0.2
#### Singularity overhaul of our RNA-seq metagenomic pipeline

VERSION='0.2'
GRN='\033[1;32m'
GRN2='\033[0;32m'
UL='\033[4;34m'
NC='\033[0m' # No Color

if (( $# < 2 ))
then
  echo
  echo "Version:"
  echo "  v$VERSION, Alexander Predeus (predeus@gmail.com), 2022-2025" 
  echo "Synopsis:"
  echo "  Accurately discover and quantify bacterial reads in bulk or 10x Chromium/Visium RNA-seq datasets."
  echo "Usage:" 
  printf "  ${GRN}dreamcatcher${NC} ${GRN2}<reads_directory> <sample> [--bulk] [--bam] [--ram RAM] [-p CPUs]${NC}\n"
  echo 
  echo "Positional arguments:"
  echo "  <reads_directory>  Directory containing samples sub-directories with either unmapped reads from STARsolo,"
  echo "                     or 10x/bulk BAM file with unmapped reads included within"
  echo "  <sample_ID>        Unique ID of the sample to be processed. This has to be a subdirectory in the <reads_directory>"
  echo 
  echo "Options:"
  echo "  --bulk             Process reads in the bulk RNA-seq mode. No UMI/barcode operations will be performed"
  echo "                     Can be used in single-end or paired-end mode. Also can be used for SMART-Seq/2/3,"
  echo "                     or other plate-based methods"
  echo "  --bam              Unmapped reads are present in a BAM file within the sample directory." 
  echo "                     Can be used in both 10x single cell and bulk RNA-seq modes"
  echo "  --ram [X]          Maximum amount of RAM available, in GB (default '100')" 
  echo "  -p [X]             Number of cores for parallel execution (default '16')"
  echo  
  printf "See ${UL}github.com/apredeus/dreamcatcher${NC} for more information.\n"
  echo 
  exit 1
fi

echo "=================================================================================="
echo "=================================================================================="
echo "===                                                                            ==="
echo "===                        Welcome to Dreamcatcher!                            ==="
echo "===           Version $VERSION - Singularity packaging, with bulk/PE support        ==="
echo "===          2022-25 (c)  Alexander Predeus, Wellcome Sanger Institute         ==="
echo "===  For more information, visit https://github.com/apredeus/dreamcatcher      ==="
echo "===         Publication in preparation (I mean it this time).                  ==="
echo "===                                                                            ==="
echo "=================================================================================="
echo "=================================================================================="
echo
echo

### these are the command line parameters with some defaults; see below

FQDIR=""
TAG=""
CPUS=16
RAM=100
BULK=false
BAM=false
PAIRED=false

#########################################################################################
########### These are the databases and files used by Dreamcatcher ######################
########### For now they are hardcoded here, but maybe should migrate to json ###########
#########################################################################################


SIF="/nfs/cellgeni/singularity/images/dreamcatcher.sif"
CMD="singularity run --bind /nfs,/lustre,/software $SIF"
NCBI="/nfs/cellgeni/refdata_dreamcatcher/NCBI_datasets/bacteria_ref/ncbi_dataset/data/"
KUDB="/nfs/cellgeni/refdata_dreamcatcher/KrakenUniq_select"
HST2T="/nfs/cellgeni/refdata_dreamcatcher/decoy_reference/T2T_mito_phix"
SEQ2TAXID="$KUDB/seqid2taxid.map.refseq"
GENBANK="$KUDB/assembly_summary_bacteria.txt"
GSA="$KUDB/gcf_species_genus.tsv"

#########################################################################################
######################## Don't change things below this line ############################
#########################################################################################

! getopt --test > /dev/null
if [[ ${PIPESTATUS[0]} -ne 4 ]]; then
    >&2 echo "ERROR: \"getopt --test\" failed in this environment"
    >&2 echo "Please make sure you have the most up-to-date version of getopt!" 
    exit 1
fi

PARSED=$(getopt -o p: --long bulk,bam,ram: -- "$@")
if [[ ${PIPESTATUS[0]} -ne 0 ]]; then
    exit 2
fi

# read getoptâ€™s output this way to handle the quoting right:
eval set -- "$PARSED"

while true
do
    case "$1" in
        --bulk)
            BULK=true
            shift 1
            ;;
        --bam)
            BAM=true
            shift 1
            ;;
        --ram)
            RAM="$2"
            shift 2
            ;;
        -p)
            CPUS="$2"
            shift 2
            ;;
        --)
            shift
            break
            ;;
        *)
            >&2 echo "ERROR: option parsing has produced an unexpected result!"
            exit 3
            ;;
    esac
done

if (( $# != 2 )) 
then
    >&2 echo "ERROR: exactly 2 positional arguments (fastq directory and sample ID) are expected! Exiting.." 
    exit 1
else
    FQDIR=$1 
    TAG=$2
    if [[ ! -d $FQDIR || ! -d $FQDIR/$TAG ]] 
    then 
        >&2 echo "ERROR: either $FQDIR or $FQDIR/$TAG directories do not exist!"
    exit 1
    fi 
fi 

RDIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
SDIR="$RDIR/scripts"

if [[ `which singularity` == "" ]]
then
    >&2 echo "ERROR: can't find Singularity! make sure you have Singularity installed and added to \$PATH in your shell! Exiting.." 
    exit 1
fi 

## export script directory and singularity command
export SDIR=$SDIR
export CMD=$CMD

if [[ $BULK == true ]]
then
    echo "==> ["`date +%H:%M:%S`"] Initiating dreamcatcher run using BULK workflow!"  
else   
    echo "==> ["`date +%H:%M:%S`"] Initiating dreamcatcher run using 10x single cell/spatial workflow!"
fi 

echo "==> ["`date +%H:%M:%S`"] Following variables were set:"
echo
echo "                             FQDIR: $FQDIR"
echo "                              SDIR: $SDIR"
echo "                         SAMPLE ID: $TAG"
echo "                              CPUS: $CPUS"
echo "                    MAXIMIM RAM(G): $RAM"
echo "                         BULK MODE: $BULK"
echo "                         BAM INPUT: $BAM"
echo "                   SINGULARITY IMG: $SIF"
echo "                   SINGULARITY CMD: $CMD"
echo "                         REFSEQ DB: $NCBI"
echo "                         KRAKEN DB: $KUDB"
echo "            SEQUENCE-TO-TAXID file: $SEQ2TAXID"
echo "             GENBANK metadata file: $GENBANK"
echo " REFSEQ-SPECIES-GENUS mapping file: $GSA"
echo "     T2T & phiX decoy hisat2 index: $HST2T"
echo

mkdir -p $TAG && cd $TAG

## step 1 is tricky and has 6 distinct cases defined by the following parameters: 
## (1) bulk/single-cell mode (2) paired-end/single-end reads (3) BAM/unmapped fastq input
## only 10x is processed in single cell mode, and 10x reads are always coerced to UMI-Tools formatted single-end reads
## bulk reads are homopolymer-filtered and discarded if too short (<40 bp). 
## single end reads are homopolymer-filtered and barcodes are corrected vs the whitelist in case of STARsolo unmapped reads 
echo "==> ["`date +%H:%M:%S`"] STEP 1: Extract and preprocess the unmapped reads for further analysis.." 
$SDIR/preprocess_unmapped_reads.sh $FQDIR $TAG $BULK $BAM 

if [[ -s Unmapped_filt.R1.fastq.gz && -s Unmapped_filt.R2.fastq.gz ]]
then
    PAIRED=true
fi

echo "==> ["`date +%H:%M:%S`"] STEP 2: Running KrakenUniq .." 
if [[ $PAIRED == false ]] 
then
    $CMD krakenuniq --threads $CPUS --db $KUDB --preload-size ${RAM}G --output kuniq.output.txt \
        --report-file kuniq.report.txt Unmapped_filt.R1.fastq.gz &> kuniq.log
    $CMD pigz kuniq.output.txt
else 
    $CMD krakenuniq --threads $CPUS --db $KUDB --preload-size ${RAM}G --output kuniq.output.txt \
        --report-file kuniq.report.txt --paired Unmapped_filt.R1.fastq.gz Unmapped_filt.R2.fastq.gz &> kuniq.log
    $CMD pigz kuniq.output.txt
fi

## KrakenUniq quits with no error and no output in some cases, still not sure why. Just re-run the job.  
if (( `cat kuniq.report.txt | wc -l` < 10 ))
then
    >&2 echo "ERROR: STEP 2 (KrakenUniq) has produced an empty report file! Exiting .." 
    exit 1
fi
## step 3: this script will find the best RefSeq genome for each detected species, using KrakenUniq output
echo "==> ["`date +%H:%M:%S`"] STEP 3: Extracting unique bacterial RefSeq accessions .."
$SDIR/kuniq_to_GCF.pl kuniq.report.txt $GSA $GENBANK > detected_strains.list 2> kuniq_to_GCF.log

## step 4: now, make a combined genome and GFF files for all strains identified by KrakenUniq
echo "==> ["`date +%H:%M:%S`"] STEP 4: Generating a combined genome and GFF file for all bacterial species .." 
$SDIR/make_combined_reference.sh $NCBI detected_strains.list detected_strains &> detected.mkref.log  

## steps 5-7: mapping to bacteria and human decoy. Notice the differential use of "-k/--max-seeds" and the relaxed soft-clipping penalty.
echo "==> ["`date +%H:%M:%S`"] STEP 5: Making combined Hisat2 index .." 
$CMD hisat2-build detected_strains.fna detected_strains &> detected.hisat2_build.log

if [[ $PAIRED == false ]] 
then 
    echo "==> ["`date +%H:%M:%S`"] STEP 6: Mapping original unmapped reads to the combined reference using Hisat2 .." 
    $CMD hisat2 -t -p$CPUS -k 5000 --sp 1,1 --no-spliced-alignment --no-unal -U Unmapped_filt.R1.fastq.gz -x \
        detected_strains 2> detected.hisat2_map.log | $CMD samtools sort -@$CPUS --verbosity 0 -O BAM - > detected_strains.bam 2> /dev/null
  
    echo "==> ["`date +%H:%M:%S`"] STEP 7: Map same corrected reads to hisat2 index of T2T assembly."
    $CMD hisat2 -t -p$CPUS -k 1 --max-seeds 1000 --sp 1,1 --no-unal -U Unmapped_filt.R1.fastq.gz -x \
        $HST2T 2> hisat2_human.log | $CMD samtools sort -@$CPUS --verbosity 0 -O BAM - > human_remap.bam 2> /dev/null
  
    echo "==> ["`date +%H:%M:%S`"] STEP 8: Running featureCounts with accurate multimapper counting; annotate each read with gene, and number of bacterial and human mismatches .." 
    $CMD featureCounts -T $CPUS -M -O --fraction -t gene -g locus_tag -s 0 -a detected_strains.gff \
        -o detected.fcounts.tsv -R BAM detected_strains.bam &> detected.fcounts.log  
    rm detected_strains.bam
    mv detected_strains.bam.featureCounts.bam detected_fcounts.bam 
  
    $SDIR/annotate_detected_reads.pl detected_fcounts.bam human_remap.bam > read_to_gene_detected_w_mismatches.tsv
else 
    echo "==> ["`date +%H:%M:%S`"] STEP 6: Mapping original unmapped reads to the combined reference using Hisat2 .." 
    $CMD hisat2 -t -p$CPUS -k 5000 --sp 1,1 --no-spliced-alignment --no-unal -1 Unmapped_filt.R1.fastq.gz -2 Unmapped_filt.R2.fastq.gz -x \
        detected_strains 2> detected.hisat2_map.log | $CMD samtools sort -@$CPUS --verbosity 0 -O BAM - > detected_strains.bam
  
    echo "==> ["`date +%H:%M:%S`"] STEP 7: Map same corrected reads to hisat2 index of T2T assembly."
    $CMD hisat2 -t -p$CPUS -k 1 --max-seeds 1000 --sp 1,1 --no-unal -1 Unmapped_filt.R1.fastq.gz -2 Unmapped_filt.R2.fastq.gz -x \
    $HST2T 2> hisat2_human.log | $CMD samtools sort -@$CPUS --verbosity 0 -O BAM - > human_remap.bam
  
    echo "==> ["`date +%H:%M:%S`"] STEP 8: Running featureCounts with accurate multimapper counting; annotate each read with gene, and number of bacterial and human mismatches .." 
    $CMD featureCounts -T $CPUS -p --countReadPairs -M -O --fraction -t gene -g locus_tag -s 0 -a detected_strains.gff \
        -o detected.fcounts.tsv -R BAM detected_strains.bam &> detected.fcounts.log
    rm detected_strains.bam
    mv detected_strains.bam.featureCounts.bam detected_fcounts.bam 
  
    $SDIR/annotate_detected_reads.pl detected_fcounts.bam human_remap.bam > read_to_gene_detected_w_mismatches.tsv
fi

### step 9: make a big table of gene biotypes; iterative regex accounts for somewhat complex range of cases that happen in GFF
echo "==> ["`date +%H:%M:%S`"] STEP 9: Making a gene biotype table .." 
$SDIR/extract_gene_biotypes.pl detected_strains.gff > gene_biotypes.tsv

## step 9: annotate the table and generate a summary per-species 
echo "==> ["`date +%H:%M:%S`"] STEP 10: Filtering/annotating the featureCounts table and generating summary per RefSeq accession .." 
$SDIR/make_summary_tables.pl detected.fcounts.tsv gene_biotypes.tsv read_to_gene_detected_w_mismatches.tsv $SEQ2TAXID

### step 10: filter the annotated table based on the number of rRNA and non-rRNA genes. files filtered.summary.tsv and filtered.gene.list would be generated
echo "==> ["`date +%H:%M:%S`"] STEP 10: Filtering the accessions: keeping strains that pass our filtering criteria.." 
cp $RDIR/data/blacklisted_genes.list .
$SDIR/filter_strains.pl detected.summary.tsv detected.annotated_fcounts.tsv blacklisted_genes.list > filter_strains.log 

if [[ ! -s filtered.summary.tsv ]]
then
    >&2 echo "ERROR: no strains have passed the filtering threshold at STEP 10! Exiting .." 
    exit 1
fi

### step 11: make the network file. use fast sort. note that we ONLY use the filtered genes to estimate the overlap etc
echo "==> ["`date +%H:%M:%S`"] STEP 11: Make the network file using the overlapping reads .." 

$SDIR/get_shared_uniq_reads.sh $CPUS 

$SDIR/make_read_network.pl read_to_gene_filtered_uniq.tsv filtered.annotated_fcounts.tsv > nodes_and_edges.tsv &
$SDIR/make_read_network.pl rRNA.shared_reads.tsv filtered.annotated_fcounts.tsv > rRNA.nodes_and_edges.tsv &
$SDIR/make_read_network.pl protein.shared_reads.tsv filtered.annotated_fcounts.tsv > protein.nodes_and_edges.tsv &
wait

echo "==> ["`date +%H:%M:%S`"] STEP 12: Parse the network and get the definitive list of strains .." 
$CMD Rscript $SDIR/parse_read_network.R $GSA &> parse_read_network.log
sort -u -t$'\t' -k15,15 --merge filtered.cluster.tsv > top.cluster.tsv

if [[ $BULK == true ]]
then
    >&2 echo "ALL DREAMCATCHER PROCESSING IN BULK MODE IS DONE! ENJOY!!!"
    exit 0
fi

echo "==> ["`date +%H:%M:%S`"] STEP 13: Making the new small bacterial reference, and mapping corrected reads to it .."
cut -f1 top.cluster.tsv | grep -v RefSeq > top_strains.list
$SDIR/make_combined_reference.sh $NCBI top_strains.list top_strains &> top.mkref.log 
$CMD hisat2-build top_strains.fna top_strains &> hisat2_build_top.log 
$CMD hisat2 -p$CPUS -k 100 --sp 1,1 --no-spliced-alignment --no-unal -U Unmapped_filt.R1.fastq.gz -x \
    top_strains 2> top.hisat2_map.log | $CMD samtools sort -@$CPUS --verbosity 0 -O BAM - > top_strains.bam 2> /dev/null

echo "==> ["`date +%H:%M:%S`"] STEP 14: Generate a new BAM file with reads assigned to genes using featureCounts .."
# 1) no strand specificity for now; 2) -M -O but without splitting - no point (UMIs will count later) 
$CMD featureCounts -T $CPUS -a top_strains.gff -t gene -g locus_tag -M -O -o top.fcounts.tsv -R BAM top_strains.bam &> top.fcounts.log
$CMD samtools sort -@$CPUS top_strains.bam.featureCounts.bam > top_assigned_sorted.bam 2> /dev/null
$CMD samtools index top_assigned_sorted.bam
rm top_strains.bam top_strains.bam.featureCounts.bam

echo "==> ["`date +%H:%M:%S`"] STEP 15: Running final quantification using UMI-tools .."
$CMD umi_tools count --per-gene --gene-tag=XT --assigned-status-tag=XS --per-cell -I top_assigned_sorted.bam -S bac_umi_counts.tsv.gz &> umi_tools_count.log 

echo "==> ["`date +%H:%M:%S`"] STEP 16: Generate barcode-to-species table from per-gene UMI-tools .." 
$SDIR/make_prefix_table.sh > prefix_to_species.tsv
$SDIR/barcode_to_species.pl bac_umi_counts.tsv.gz prefix_to_species.tsv > barcode_to_species.tsv

echo "==> ["`date +%H:%M:%S`"] STEP 17: Tidy up the output directories .." 
$SDIR/organise_output_dir.sh $BULK 

echo "ALL DREAMCATCHER PROCESSING IS DONE! ENJOY!!!" 
